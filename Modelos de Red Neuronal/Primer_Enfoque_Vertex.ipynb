{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ng4zAw29_qE5",
        "1mZkQ_AZRQyu",
        "qYeUCdDnRhDc",
        "1vbPcV03U4Zr",
        "agTqtO6UU4Zy",
        "oB7sGXg5l6ya",
        "9dl2X1xWRG7D",
        "kh4Ub_LWRG7H",
        "RzuiVzs2Sl-z",
        "paEya3YZF7Yi"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Inicialización"
      ],
      "metadata": {
        "id": "ZH6MfWwi7tSk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "random_state = 33"
      ],
      "metadata": {
        "id": "HN4sfCSZwW4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Para acceder a los ficheros de Google Drive\n",
        "drive.mount('/content/drive')\n",
        "# La carpeta datos debe estar en vuestro Drive, dentro de la carpeta 'Colab Notebooks'"
      ],
      "metadata": {
        "id": "63VrcRrnwW4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Función Pasar de vector codificado a matriz de adyacencia"
      ],
      "metadata": {
        "id": "ng4zAw29_qE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convertir_vector_matriz(caso, N):\n",
        "  vector = caso[:int(N*(N-1)/2)]\n",
        "  #Inicializar la matriz de adyacencia\n",
        "  matriz_ad = [[False for _ in range(N)] for _ in range(N)]\n",
        "  index = 0  # Índice para recorrer el vector\n",
        "  for i in range(N):\n",
        "      for j in range(i + 1, N):  # Empezar desde i+1 para omitir la diagonal\n",
        "          if vector[index]:  # Si el valor en el vector es True\n",
        "              matriz_ad[i][j] = True\n",
        "              matriz_ad[j][i] = True  # Rellenar el valor simétrico para la matriz no dirigida\n",
        "          index += 1\n",
        "  return matriz_ad"
      ],
      "metadata": {
        "id": "FODwkL7hT4Wa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Experimento Vertex Cover $N=20$ y $10^5$ casos"
      ],
      "metadata": {
        "id": "yjsFNw27l6yW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Debido al alto coste computacional de entrenar las redes neuronales, ejecutar etse experimento lleva una cantidad considerable de horas."
      ],
      "metadata": {
        "id": "e6lOfpL4N3Ig"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El problema utiliza $N$ objetos exactamente y los datos se cargan desde un fichero .csv como un vector de X casos y cada posición es un vector de $4N+2$ variables que representan:   \n",
        "\n",
        "- 0 : Número de vértices\n",
        "- $1$ - $(\\frac{(N(N-1))}{2})$   : Mitad triangular superior de la matriz de adyacencia.\n",
        "\n",
        "- $(\\frac{(N(N-1))}{2}+1)$  -  $(\\frac{(N(N-1))}{2} + N+1)$ : Vector binario solucion peor.  \n",
        "- $(\\frac{(N(N-1))}{2} + N+1)$  -  $(\\frac{(N(N-1))}{2} + 2N+1)$ : Vector binario de solucion mejor.\n",
        "\n"
      ],
      "metadata": {
        "id": "CNsm8GL4l6yX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cargar Datos"
      ],
      "metadata": {
        "id": "1mZkQ_AZRQyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'drive/MyDrive/Colab Notebooks/datos/TFG/data_E1_VertexCover.csv'\n",
        "\n",
        "datos_originales = np.genfromtxt(file_path, delimiter=\",\") #Funcion cargar datos desde txt, y en este caso desde csv\n"
      ],
      "metadata": {
        "id": "3qUNh5amVkzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comprobación y eliminación de Duplicados en los datos"
      ],
      "metadata": {
        "id": "h20cx2WTWKtP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Comprobando duplicados en datos\n",
        "unique_rows, indices = np.unique(datos_originales, axis=0, return_index=True)\n",
        "num_duplicates = datos_originales.shape[0] - unique_rows.shape[0]\n",
        "\n",
        "print(\"Número de filas duplicadas en los datos:\", num_duplicates)\n",
        "\n",
        "# Eliminar duplicados\n",
        "datos = datos_originales[np.sort(indices)]\n",
        "\n",
        "\n",
        "unique_rows, indices = np.unique(datos, axis=0, return_index=True)\n",
        "num_duplicates = datos.shape[0] - unique_rows.shape[0]\n",
        "\n",
        "print(\"Número de filas duplicadas en los datos despúes de eliminar duplicados:\", num_duplicates)"
      ],
      "metadata": {
        "id": "m3P37ERsVrWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numItems = datos[0][0]\n",
        "tamMatriz = numItems*(numItems-1)/2\n",
        "x = datos[:, 1: int(tamMatriz+numItems+1)]  # datos de entrada\n",
        "y = datos[:, int(tamMatriz+numItems+1):]   # datos de etiqueta\n",
        "x = np.array(x, np.float64)\n",
        "y = np.array(y, np.float64)\n",
        "\n",
        "print(\"Número de objetos (N) =\", numItems)\n",
        "# Mostrar dimension del conjunto de muestras total\n",
        "print(\"Forma de vector X de muestras:\", x.shape)\n",
        "print(\"Forma de vector Y de etiquetas:\", y.shape)\n",
        "print(\"Forma de vector datos:\", datos.shape)\n",
        "\n",
        "print(\"Ejemplos:\")\n",
        "print(\"X = \",x[0])\n",
        "print(\"Y = \",y[0])"
      ],
      "metadata": {
        "id": "24o2xIH_l6yY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Separación de datos en Train y Test"
      ],
      "metadata": {
        "id": "qYeUCdDnRhDc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Separo el conjunto de casos en test y train para evaluar los modelos utilizados. También se pueden utilizar funciones como `sklearn.model_selection.train_test_split()` pero de esta forma se pueden guardar los índices para realizar comprobaciones de forma más sencilla."
      ],
      "metadata": {
        "id": "QlxPrefLRhDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Separate data in test and train\n",
        "\n",
        "np.random.seed(33)\n",
        "trainPortion = 0.8 #porcentaje de train, el porcentaje de test será la resta de 1 menos el porcentaje de train\n",
        "\n",
        "#-------------Obtener índices\n",
        "\n",
        "indexesData = np.arange(len(y)) #Indices del conjunto de muestras\n",
        "#-------------Desordenar indices y separar en rain y test\n",
        "\n",
        "np.random.shuffle(indexesData) #Desordenar indices de las muestras\n",
        "numberTrain = round(len(indexesData)*trainPortion) #numero de muestras para train\n",
        "trainIndexes = indexesData[:numberTrain]\n",
        "testIndexes = indexesData[numberTrain:]\n",
        "\n",
        "#-------------Datos desorden:ados para train y test\n",
        "\n",
        "trainX = x[trainIndexes]\n",
        "testX = x[testIndexes]\n",
        "trainY = y[trainIndexes]\n",
        "testY = y[testIndexes]\n",
        "\n",
        "#-------------Copia de los datos para mantener datos originales después del preprocesado\n",
        "\n",
        "original_trainX = trainX.copy()\n",
        "original_testX = testX.copy()\n",
        "original_trainY = trainY.copy()\n",
        "original_testY = testY.copy()\n",
        "\n",
        "#-------------Mostrar resultados\n",
        "\n",
        "print('Muestras totales:  {}'.format(len(trainY)+len(testX)))\n",
        "print('Muestras train:  {}'.format(len(trainY)))\n",
        "print('Muestras test:  {}'.format(len(testX)))\n"
      ],
      "metadata": {
        "id": "qgP4q9xyl6yY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocesamiento de los datos"
      ],
      "metadata": {
        "id": "1vbPcV03U4Zr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como los datos han sido generados artificialmente y no se han obtenido de fuentes externas, no es necesario realizar la búsqueda de datos faltantes o erroneos ni desbalanceo en las proporciones ya que los datos han sido generados teniendo en cuenta estos factores. La codificación de los datos también se ha tenido en cuenta en al generación de los datos."
      ],
      "metadata": {
        "id": "ZuahfourU4Zy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comprobación de Duplicados en los datos"
      ],
      "metadata": {
        "id": "ET0R8AbbU4Zy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Comprobando duplicados en datos\n",
        "unique_rows= np.unique(datos, axis=0)\n",
        "num_duplicates = datos.shape[0] - unique_rows.shape[0]\n",
        "\n",
        "print(\"Número de filas duplicadas en los datos:\", num_duplicates)"
      ],
      "metadata": {
        "id": "DCaZy95KU4Zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Escalar Datos"
      ],
      "metadata": {
        "id": "agTqtO6UU4Zy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este problema no hace falta escalar los datos"
      ],
      "metadata": {
        "id": "a_0pyRNe3wYt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Funciones y Metrica fitness"
      ],
      "metadata": {
        "id": "oB7sGXg5l6ya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def valor_fitness(instancia, caso):\n",
        "  instancia_local = instancia.copy()\n",
        "  N = len(instancia_local)\n",
        "  sin_cubrir = convertir_vector_matriz(caso,N)\n",
        "  #sin_cubrir = copy.deepcopy(matriz_ad)\n",
        "\n",
        "  # Iterar sobre la solución inicial y marcar las aristas cubiertas\n",
        "  for i, cubierto in enumerate(instancia_local):\n",
        "      if cubierto:\n",
        "          for j in range(N):  # Modificar sin usar sintaxis de NumPy\n",
        "                sin_cubrir[j][i] = False\n",
        "                sin_cubrir[i][j] = False\n",
        "\n",
        "  # Verificar aristas restantes y añadir vértices a la solución si es necesario\n",
        "  for i in range(N):\n",
        "      for j in range(i + 1, N):\n",
        "          if sin_cubrir[i][j]:  # Si la arista entre i y j no está cubierta\n",
        "              instancia_local[i] = True\n",
        "              for k in range(N):  # Modificar sin usar sintaxis de NumPy\n",
        "                  sin_cubrir[k][i] = False\n",
        "                  sin_cubrir[i][k] = False\n",
        "  return np.sum(instancia_local)\n",
        "\n",
        "def metrica_valor_fitness_entrada(y_true, y_pred, x):\n",
        "  mejora = 0\n",
        "  num_aciertos = 0\n",
        "  num_tot = len(x)\n",
        "  num_items = len(y_pred[0])\n",
        "  umbral = 0.5\n",
        "  predictions_binary = (y_pred >= umbral).astype(int)\n",
        "  for i in range(num_tot):\n",
        "    #valor_salida_real = np.sum(y_true)\n",
        "    valor_salida_pred = valor_fitness(y_pred[i],x[i])\n",
        "    valor_entrada = np.sum(x[i][int(num_items*(num_items-1)/2):])\n",
        "    mejora += valor_salida_pred / valor_entrada\n",
        "  return mejora/num_tot\n",
        "\n",
        "def metrica_valor_fitness_salida(y_true, y_pred, x):\n",
        "  mejora = 0\n",
        "  num_aciertos = 0\n",
        "  num_tot = len(x)\n",
        "  num_items = len(y_pred[0])\n",
        "  umbral = 0.5\n",
        "  predictions_binary = (y_pred >= umbral).astype(int)\n",
        "  for i in range(num_tot):\n",
        "    valor_salida_real = np.sum(y_true[i])\n",
        "    valor_salida_pred = valor_fitness(y_pred[i],x[i])\n",
        "    #valor_entrada = np.sum(x[i][int(num_items*(num_items-1)/2):])\n",
        "    if(valor_salida_real == 0):\n",
        "      mejora += valor_salida_pred\n",
        "    else:  mejora += valor_salida_pred / valor_salida_real\n",
        "  return mejora/num_tot\n",
        "\n",
        "\n",
        "def metrica_porcentaje_mejor_entrada(y_true, y_pred, x):\n",
        "  num_aciertos = 0\n",
        "  num_tot = len(x)\n",
        "  num_items = len(y_pred[0])\n",
        "  umbral = 0.5\n",
        "  predictions_binary = (y_pred >= umbral).astype(int)\n",
        "  for i in range(num_tot):\n",
        "    #valor_salida_real = np.sum(y_true)\n",
        "    valor_salida_pred = valor_fitness(y_pred[i],x[i])\n",
        "    valor_entrada = np.sum(x[i][int(num_items*(num_items-1)/2):])\n",
        "    if valor_salida_pred < valor_entrada:\n",
        "      num_aciertos += 1\n",
        "  return num_aciertos/num_tot\n",
        "\n",
        "\n",
        "def metrica_porcentaje_mejor_salida(y_true, y_pred, x):\n",
        "  num_aciertos = 0\n",
        "  num_tot = len(x)\n",
        "  num_items = len(y_pred[0])\n",
        "  umbral = 0.5\n",
        "  predictions_binary = (y_pred >= umbral).astype(int)\n",
        "  for i in range(num_tot):\n",
        "    valor_salida_real = np.sum(y_true[i])\n",
        "    #print(y_true,valor_salida_real)\n",
        "    valor_salida_pred = valor_fitness(y_pred[i],x[i])\n",
        "    #valor_salida = np.sum(x[i][int(num_items*(num_items-1)/2):])\n",
        "    if valor_salida_pred < valor_salida_real:\n",
        "      num_aciertos += 1\n",
        "  return num_aciertos/num_tot\n",
        "\n",
        "\n",
        "def metrica_porcentaje_mejor_igual_entrada(y_true, y_pred, x):\n",
        "  num_aciertos = 0\n",
        "  num_tot = len(x)\n",
        "  num_items = len(y_pred[0])\n",
        "  umbral = 0.5\n",
        "  predictions_binary = (y_pred >= umbral).astype(int)\n",
        "  for i in range(num_tot):\n",
        "    #valor_salida_real = np.sum(y_true)\n",
        "    valor_salida_pred = valor_fitness(y_pred[i],x[i])\n",
        "    valor_entrada = np.sum(x[i][int(num_items*(num_items-1)/2):])\n",
        "    if valor_salida_pred <= valor_entrada:\n",
        "      num_aciertos += 1\n",
        "  return num_aciertos/num_tot\n",
        "\n",
        "def metrica_porcentaje_mejor_igual_salida(y_true, y_pred, x):\n",
        "  num_aciertos = 0\n",
        "  num_tot = len(x)\n",
        "  num_items = len(y_pred[0])\n",
        "  umbral = 0.5\n",
        "  predictions_binary = (y_pred >= umbral).astype(int)\n",
        "  for i in range(num_tot):\n",
        "    valor_salida_real = np.sum(y_true[i])\n",
        "    #print(y_true,valor_salida_real)\n",
        "    valor_salida_pred = valor_fitness(y_pred[i],x[i])\n",
        "    #valor_salida = np.sum(x[i][int(num_items*(num_items-1)/2):])\n",
        "    if valor_salida_pred <= valor_salida_real:\n",
        "      num_aciertos += 1\n",
        "  return num_aciertos/num_tot\n",
        "\n"
      ],
      "metadata": {
        "id": "5kLh2MTel6ya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Ratio de mejora de las soluciones etiquetas respecto de las soluciones iniciales:\",metrica_valor_fitness_entrada(trainY,trainY,trainX))\n",
        "print(\"Porcentaje de soluciones etiquetas mejores estricto que las soluciones iniciales:\",metrica_porcentaje_mejor_entrada(trainY,trainY,trainX)*100,\"%\")\n",
        "print(\"Porcentaje de soluciones etiquetas mejores o iguales que las soluciones iniciales:\",metrica_porcentaje_mejor_igual_entrada(trainY,trainY,trainX)*100,\"%\")"
      ],
      "metadata": {
        "id": "738MS2fAh4CJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creación del Modelo"
      ],
      "metadata": {
        "id": "9dl2X1xWRG7D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Valores de entrada y salida de los modelos:"
      ],
      "metadata": {
        "id": "6z6C6inrRG7E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbCF9KoARG7E"
      },
      "outputs": [],
      "source": [
        "input_shape  = tamMatriz + numItems\n",
        "output_shape = numItems  #  Numero de valores a predecir (la solucion al problema)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a implementar una función que nos cree el modelo que vamos a entrenar y evaluar."
      ],
      "metadata": {
        "id": "vdx3rjGARG7E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLEqyMm7RG7E"
      },
      "outputs": [],
      "source": [
        "def create_model(dense_neurons, input_shape, output_shape):\n",
        "    local_model = keras.Sequential()\n",
        "\n",
        "    # Capa de entrada\n",
        "    local_model.add(layers.Input(shape=(int(input_shape),)))\n",
        "\n",
        "    # capas ocultas con activación Relu\n",
        "    for neurons in dense_neurons:\n",
        "      local_model.add(layers.Dense(neurons, activation='relu'))\n",
        "\n",
        "    # Capa de salida para clasificación con tantas neuronas como salidas esperadas\n",
        "    local_model.add(layers.Dense(output_shape, activation='sigmoid'))\n",
        "    return local_model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Grid Search"
      ],
      "metadata": {
        "id": "2_xbt1cQTPXd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos la función para utilizar grid_search"
      ],
      "metadata": {
        "id": "bDYdiMQDTPXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def single_grid_search(dense_neurons, input_shape, output_shape, X, Y, epochs, batch_size, learn_rate, _n_splits = 5, _random_state = 33):\n",
        "\n",
        "    # Inicializar KFold\n",
        "    kfold = KFold(n_splits=_n_splits, shuffle=True, random_state=_random_state)\n",
        "\n",
        "    accuracy_results = []\n",
        "    loss_results = []\n",
        "    mejora_entrada_results = []\n",
        "    mejora_salida_results = []\n",
        "    porc_mejor_entrada_results = []\n",
        "    porc_mejor_salida_results = []\n",
        "    porc_mejor_igual_entrada_results = []\n",
        "    porc_mejor_igual_salida_results = []\n",
        "\n",
        "    # Iterar sobre cada fold (validación cruzada)\n",
        "    for train_index, test_index in kfold.split(X):\n",
        "        # Dividir datos en entrenamiento y prueba\n",
        "        trainX, valX = X[train_index], X[test_index]\n",
        "        trainY, valY = Y[train_index], Y[test_index]\n",
        "\n",
        "        # Crear modelo\n",
        "        local_model = create_model(dense_neurons, input_shape, output_shape)\n",
        "\n",
        "        # Compilar el modelo\n",
        "        sgd_optimizer = SGD(learning_rate=learn_rate)\n",
        "        local_model.compile(optimizer=sgd_optimizer,\n",
        "                            loss='binary_crossentropy',\n",
        "                            metrics=['accuracy'])\n",
        "\n",
        "        # Entrenar el modelo\n",
        "        local_model.fit(\n",
        "            trainX, trainY,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            verbose=0,\n",
        "        )\n",
        "\n",
        "        # Evaluar el modelo\n",
        "        scores = local_model.evaluate(valX, valY, verbose=0)\n",
        "        loss_results.append(scores[0])\n",
        "        accuracy_results.append(scores[1])\n",
        "\n",
        "        # Evaluar metricas personalizadas\n",
        "        y_pred = local_model.predict(valX,verbose=0)\n",
        "        umbral = 0.5\n",
        "        y_pred_binary = (y_pred >= umbral).astype(int)\n",
        "\n",
        "        mejora_entrada_results.append(metrica_valor_fitness_entrada(valY,y_pred_binary,valX))\n",
        "        mejora_salida_results.append(metrica_valor_fitness_salida(valY,y_pred_binary,valX))\n",
        "        porc_mejor_entrada_results.append(metrica_porcentaje_mejor_entrada(valY,y_pred_binary,valX))\n",
        "        porc_mejor_salida_results.append(metrica_porcentaje_mejor_salida(valY,y_pred_binary,valX))\n",
        "        porc_mejor_igual_entrada_results.append(metrica_porcentaje_mejor_igual_entrada(valY, y_pred_binary, valX))\n",
        "        porc_mejor_igual_salida_results.append(metrica_porcentaje_mejor_igual_salida(valY, y_pred_binary, valX))\n",
        "\n",
        "    # Devolver el promedio de las evaluaciones\n",
        "    return np.mean(loss_results), np.mean(accuracy_results),np.mean(mejora_entrada_results),np.mean(mejora_salida_results),np.mean(porc_mejor_entrada_results),np.mean(porc_mejor_salida_results), np.mean(porc_mejor_igual_entrada_results), np.mean(porc_mejor_igual_salida_results), loss_results"
      ],
      "metadata": {
        "id": "U7d7ht3HTPXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Valores de los hiperparámetros a probar:"
      ],
      "metadata": {
        "id": "DYNnMTNITPXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Valores de los hiperparámetros para el modelo base\n",
        "dense_neurons  = (numItems*numItems,numItems*numItems,numItems*numItems/2,numItems*2)\n",
        "epochs = 100\n",
        "learning_rate = 0.1\n",
        "batch_size = 64\n",
        "k_folds = 2\n",
        "\n",
        "# Valores de los  distintos hiperparámetros\n",
        "learning_rate_search  = [0.1,0.01,0.001,0.0001,0.00001]\n",
        "batch_size_search = [16,32,64,96,128]"
      ],
      "metadata": {
        "id": "DO0LIXCFTPXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Hiperparámetro de la tasa de aprendizaje (learning rate)"
      ],
      "metadata": {
        "id": "7BhePonVTPXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_mean_table = []\n",
        "loss_mean_table = []\n",
        "mejora_entrada_table = []\n",
        "mejora_salida_table = []\n",
        "porc_mejor_entrada_table = []\n",
        "porc_mejor_salida_table = []\n",
        "porc_mejor_igual_entrada_table = []\n",
        "porc_mejor_igual_salida_table = []\n",
        "\n",
        "for lr in learning_rate_search:\n",
        "    # Entrenar y evaluar\n",
        "    results = single_grid_search(dense_neurons, input_shape, output_shape, trainX, trainY, epochs, batch_size, lr, k_folds, random_state)\n",
        "\n",
        "    loss_mean_table.append(results[0])\n",
        "    accuracy_mean_table.append(results[1])\n",
        "    mejora_entrada_table.append(results[2])\n",
        "    mejora_salida_table.append(results[3])\n",
        "    porc_mejor_entrada_table.append(results[4])\n",
        "    porc_mejor_salida_table.append(results[5])\n",
        "    porc_mejor_igual_entrada_table.append(results[6])\n",
        "    porc_mejor_igual_salida_table.append(results[7])\n",
        "\n",
        "\n",
        "#Crear DataFrame y mostrarlo\n",
        "tableFrame = pd.DataFrame({'Tasa de Aprendizaje': learning_rate_search,'Error de validación(función de pérdida)':loss_mean_table,'Accuracy':accuracy_mean_table,'Mejora Solucion Incial':mejora_entrada_table,\n",
        "                           'Mejora Solucion Etiqueta':mejora_salida_table,'Porc Mejores estricto que Inicial':porc_mejor_entrada_table,'Porc Mejores o iguales que Inicial':porc_mejor_igual_entrada_table,\n",
        "                           'Porc Mejores que Etiqueta':porc_mejor_salida_table, 'Porc Mejores o iguales que Etiqueta':porc_mejor_igual_salida_table})\n",
        "display(tableFrame)"
      ],
      "metadata": {
        "id": "0MLFnCO9TPXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Hiperparámetro del tamaño de lote (batch size)"
      ],
      "metadata": {
        "id": "6ce_OOIWTPXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_mean_table = []\n",
        "loss_mean_table = []\n",
        "mejora_entrada_table = []\n",
        "mejora_salida_table = []\n",
        "porc_mejor_entrada_table = []\n",
        "porc_mejor_salida_table = []\n",
        "porc_mejor_igual_entrada_table = []\n",
        "porc_mejor_igual_salida_table = []\n",
        "\n",
        "for bs in batch_size_search:\n",
        "    # Entrenar y evaluar\n",
        "    results = single_grid_search(dense_neurons, input_shape, output_shape, trainX, trainY, epochs, bs, learning_rate, k_folds, random_state)\n",
        "\n",
        "    loss_mean_table.append(results[0])\n",
        "    accuracy_mean_table.append(results[1])\n",
        "    mejora_entrada_table.append(results[2])\n",
        "    mejora_salida_table.append(results[3])\n",
        "    porc_mejor_entrada_table.append(results[4])\n",
        "    porc_mejor_salida_table.append(results[5])\n",
        "    porc_mejor_igual_entrada_table.append(results[6])\n",
        "    porc_mejor_igual_salida_table.append(results[7])\n",
        "\n",
        "\n",
        "#Crear DataFrame y mostrarlo\n",
        "tableFrame = pd.DataFrame({'Tamaño de Lote': batch_size_search,'Error de validación(función de pérdida)':loss_mean_table,'Accuracy':accuracy_mean_table,'Mejora Solucion Incial':mejora_entrada_table,\n",
        "                           'Mejora Solucion Etiqueta':mejora_salida_table,'Porc Mejores estricto que Inicial':porc_mejor_entrada_table,'Porc Mejores o iguales que Inicial':porc_mejor_igual_entrada_table,\n",
        "                           'Porc Mejores que Etiqueta':porc_mejor_salida_table, 'Porc Mejores o iguales que Etiqueta':porc_mejor_igual_salida_table})\n",
        "display(tableFrame)"
      ],
      "metadata": {
        "id": "EGfKX18RTPXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelo Final"
      ],
      "metadata": {
        "id": "qke6IlfjRG7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Valores de los hiperparámetros para el modelo final\n",
        "dense_neurons  = (numItems*numItems,numItems*numItems,numItems*numItems/2,numItems*2)\n",
        "batch_size = 16\n",
        "epochs = 200\n",
        "learning_rate = 0.1\n",
        "\n",
        "\n",
        "final_model = create_model(dense_neurons, input_shape, output_shape)\n",
        "\n",
        "# Compilar el modelo\n",
        "sgd_optimizer = SGD(learning_rate=learning_rate)\n",
        "final_model.compile(optimizer=sgd_optimizer,\n",
        "                    loss='binary_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "# Entrenar el modelo\n",
        "final_model.fit(\n",
        "    trainX, trainY,\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    verbose=2,\n",
        ")"
      ],
      "metadata": {
        "id": "NlneQQLdRG7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resultados"
      ],
      "metadata": {
        "id": "viMimYmFRG7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_mean_table = []\n",
        "mejora_entrada_table = []\n",
        "mejora_salida_table = []\n",
        "porc_mejor_entrada_table = []\n",
        "porc_mejor_salida_table = []\n",
        "porc_mejor_igual_entrada_table = []\n",
        "porc_mejor_igual_salida_table = []\n",
        "loss_mean_table = []\n",
        "\n",
        "# Evaluar el modelo\n",
        "scores = final_model.evaluate(testX, testY, verbose=0)\n",
        "loss_mean_table.append(scores[0])\n",
        "accuracy_mean_table.append(scores[1])\n",
        "\n",
        "# Evaluar metricas personalizadas\n",
        "y_pred = final_model.predict(testX,verbose=0)\n",
        "umbral = 0.5\n",
        "y_pred_binary = (y_pred >= umbral).astype(int)\n",
        "\n",
        "mejora_entrada_table.append(metrica_valor_fitness_entrada(testY, y_pred_binary, testX))\n",
        "mejora_salida_table.append(metrica_valor_fitness_salida(testY, y_pred_binary, testX))\n",
        "porc_mejor_entrada_table.append(metrica_porcentaje_mejor_entrada(testY, y_pred_binary, testX))\n",
        "porc_mejor_salida_table.append(metrica_porcentaje_mejor_salida(testY, y_pred_binary, testX))\n",
        "porc_mejor_igual_entrada_table.append(metrica_porcentaje_mejor_igual_entrada(testY, y_pred_binary, testX))\n",
        "porc_mejor_igual_salida_table.append(metrica_porcentaje_mejor_igual_salida(testY, y_pred_binary, testX))\n",
        "\n",
        "\n",
        "#Crear DataFrame y mostrarlo\n",
        "tableFrame = pd.DataFrame({'Error de test (función de pérdida)':loss_mean_table,'Accuracy':accuracy_mean_table,'Mejora Solucion Incial':mejora_entrada_table,\n",
        "                           'Mejora Solucion Etiqueta':mejora_salida_table,'Porc Mejores estricto que Inicial':porc_mejor_entrada_table,'Porc Mejores o igual que Inicial':porc_mejor_igual_entrada_table,\n",
        "                           'Porc Mejores que Etiqueta':porc_mejor_salida_table, 'Porc Mejores o igual que Etiqueta':porc_mejor_igual_salida_table})\n",
        "display(tableFrame)"
      ],
      "metadata": {
        "id": "XTJOen7CRG7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Curvas de Aprendizaje"
      ],
      "metadata": {
        "id": "XWfwNCysRG7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_learning_curves_mejora(curves_model, train_X, train_Y, val_X, val_Y, batch_size,epochs, iters):\n",
        "    accuracy_results = [[],[]]\n",
        "    loss_results = [[],[]]\n",
        "    mejora_entrada_results = [[],[]]\n",
        "    mejora_salida_results = [[],[]]\n",
        "    porc_mejor_entrada_results = [[],[]]\n",
        "    porc_mejor_salida_results = [[],[]]\n",
        "    porc_mejor_igual_entrada_results = [[],[]]\n",
        "    porc_mejor_igual_salida_results = [[],[]]\n",
        "\n",
        "    for i in range(iters):\n",
        "        # Entrenar el modelo\n",
        "        curves_model.fit(\n",
        "            train_X, train_Y,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            verbose=2,\n",
        "        )\n",
        "\n",
        "        e_type = 0 # Entrenameinto\n",
        "        # Evaluar el modelo\n",
        "        scores = curves_model.evaluate(train_X, train_Y, verbose=0)\n",
        "        loss_results[e_type].append(scores[0])\n",
        "        accuracy_results[e_type].append(scores[1])\n",
        "\n",
        "        # Evaluar metricas personalizadas\n",
        "        y_pred = curves_model.predict(train_X,verbose=0)\n",
        "        umbral = 0.5\n",
        "        y_pred_binary = (y_pred >= umbral).astype(int)\n",
        "\n",
        "        mejora_entrada_results[e_type].append(metrica_valor_fitness_entrada(train_Y,y_pred_binary,train_X))\n",
        "        mejora_salida_results[e_type].append(metrica_valor_fitness_salida(train_Y,y_pred_binary,train_X))\n",
        "        porc_mejor_entrada_results[e_type].append(metrica_porcentaje_mejor_entrada(train_Y,y_pred_binary,train_X))\n",
        "        porc_mejor_salida_results[e_type].append(metrica_porcentaje_mejor_salida(train_Y,y_pred_binary,train_X))\n",
        "        porc_mejor_igual_entrada_results[e_type].append(metrica_porcentaje_mejor_igual_entrada(train_Y,y_pred_binary,train_X))\n",
        "        porc_mejor_igual_salida_results[e_type].append(metrica_porcentaje_mejor_igual_salida(train_Y,y_pred_binary,train_X))\n",
        "\n",
        "\n",
        "        e_type = 1 # Validación\n",
        "        # Evaluar el modelo\n",
        "        scores = curves_model.evaluate(val_X, val_Y, verbose=0)\n",
        "        loss_results[e_type].append(scores[0])\n",
        "        accuracy_results[e_type].append(scores[1])\n",
        "\n",
        "        # Evaluar metricas personalizadas\n",
        "        y_pred = curves_model.predict(val_X,verbose=0)\n",
        "        umbral = 0.5\n",
        "        y_pred_binary = (y_pred >= umbral).astype(int)\n",
        "\n",
        "        mejora_entrada_results[e_type].append(metrica_valor_fitness_entrada(val_Y,y_pred_binary,val_X))\n",
        "        mejora_salida_results[e_type].append(metrica_valor_fitness_salida(val_Y,y_pred_binary,val_X))\n",
        "        porc_mejor_entrada_results[e_type].append(metrica_porcentaje_mejor_entrada(val_Y,y_pred_binary,val_X))\n",
        "        porc_mejor_salida_results[e_type].append(metrica_porcentaje_mejor_salida(val_Y,y_pred_binary,val_X))\n",
        "        porc_mejor_igual_entrada_results[e_type].append(metrica_porcentaje_mejor_igual_entrada(val_Y,y_pred_binary,val_X))\n",
        "        porc_mejor_igual_salida_results[e_type].append(metrica_porcentaje_mejor_igual_salida(val_Y,y_pred_binary,val_X))\n",
        "\n",
        "    return accuracy_results, loss_results, mejora_entrada_results, mejora_salida_results, porc_mejor_entrada_results, porc_mejor_salida_results, porc_mejor_igual_entrada_results, porc_mejor_igual_salida_results\n",
        "\n",
        "\n",
        "dense_neurons  = (numItems*numItems,numItems*numItems,numItems*numItems/2,numItems*2)\n",
        "batch_size = 16\n",
        "learning_rate = 0.1\n",
        "curves_model = create_model(dense_neurons, input_shape, output_shape)\n",
        "\n",
        "# Compilar el modelo\n",
        "sgd_optimizer = SGD(learning_rate=learning_rate)\n",
        "curves_model.compile(optimizer=sgd_optimizer,\n",
        "                    loss='binary_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "epochs = 5\n",
        "iters = 20\n",
        "curves_results = create_learning_curves_mejora(curves_model, trainX, trainY, testX,testY, batch_size, epochs,iters)"
      ],
      "metadata": {
        "id": "FsIAENFwRG7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_mean_table = []\n",
        "mejora_entrada_table = []\n",
        "mejora_salida_table = []\n",
        "porc_mejor_entrada_table = []\n",
        "porc_mejor_salida_table = []\n",
        "loss_mean_table = []\n",
        "\n",
        "# Evaluar el modelo\n",
        "scores = curves_model.evaluate(testX, testY, verbose=0)\n",
        "loss_mean_table.append(scores[0])\n",
        "accuracy_mean_table.append(scores[1])\n",
        "\n",
        "# Evaluar metricas personalizadas\n",
        "y_pred = curves_model.predict(testX,verbose=0)\n",
        "\n",
        "umbral = 0.5\n",
        "y_pred_binary = (y_pred >= umbral).astype(int)\n",
        "mejora_entrada_table.append(metrica_valor_fitness_entrada(testY,y_pred_binary,testX))\n",
        "mejora_salida_table.append(metrica_valor_fitness_salida(testY,y_pred_binary,testX))\n",
        "porc_mejor_entrada_table.append(metrica_porcentaje_mejor_entrada(testY,y_pred_binary,testX))\n",
        "porc_mejor_salida_table.append(metrica_porcentaje_mejor_salida(testY,y_pred_binary,testX))\n",
        "\n",
        "\n",
        "#Crear DataFrame y mostrarlo\n",
        "tableFrame = pd.DataFrame({'Error de validación medio (función de pérdida)':loss_mean_table,'Accuracy medio':accuracy_mean_table,'Mejora Solucion Incial':mejora_entrada_table,\n",
        "                           'Mejora Solucion Etiqueta':mejora_salida_table,'Porc Mejores que Inicial':porc_mejor_entrada_table, 'Porc Mejores que Etiqueta':porc_mejor_salida_table})\n",
        "display(tableFrame)"
      ],
      "metadata": {
        "id": "enHRgrD7RG7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ratio de mejora soluciones Iniciales"
      ],
      "metadata": {
        "id": "u5PGIPB_RG7H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 7))\n",
        "plt.title(\"Curva de Aprendizaje de la Mejora respecto de las Soluciones Iniciales\",fontsize = 15)\n",
        "plt.xlabel(\"Época\",fontsize = 15)\n",
        "plt.ylabel(\"Ratio de Mejora\",fontsize = 15)\n",
        "plt.plot(range(epochs, epochs*(iters+1),epochs), curves_results[2][0], 'b',label=r'$Mejora_{in}$', linewidth=2)\n",
        "plt.plot(range(epochs, epochs*(iters+1),epochs), curves_results[2][1], 'orange',label=r'$Mejora_{out}$', linewidth=2)\n",
        "\n",
        "plt.legend(fontsize = 15)\n",
        "plt.grid(visible=True,linewidth=0.2) # poner la cuadricula con el grosor del resultado dado\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lrQU-cP6RG7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ratio de mejora soluciones Etiquetas"
      ],
      "metadata": {
        "id": "kh4Ub_LWRG7H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 7))\n",
        "plt.title(\"Curva de Aprendizaje de la Mejora respecto de las Soluciones Etiquetas\",fontsize = 15)\n",
        "plt.xlabel(\"Época\",fontsize = 15)\n",
        "plt.ylabel(\"Ratio de Mejora\",fontsize = 15)\n",
        "plt.plot(range(epochs, epochs*(iters+1),epochs), curves_results[3][0], 'b',label=r'$Mejora_{in}$', linewidth=2)\n",
        "plt.plot(range(epochs, epochs*(iters+1),epochs), curves_results[3][1], 'orange',label=r'$Mejora_{out}$', linewidth=2)\n",
        "\n",
        "plt.legend(fontsize = 15)\n",
        "plt.grid(visible=True,linewidth=0.2) # poner la cuadricula con el grosor del resultado dado\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vbOpoS52RG7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Porcentaje de soluciones mejores que Iniciales"
      ],
      "metadata": {
        "id": "EkmCcBDGRG7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 7))\n",
        "plt.title(\"Curva de Aprendizaje del Porcentaje de Mejores soluciones respecto de las Iniciales\",fontsize = 15)\n",
        "plt.xlabel(\"Época\",fontsize = 15)\n",
        "plt.ylabel(\"Porcentaje de Mejores soluciones\",fontsize = 15)\n",
        "plt.plot(range(epochs, epochs*(iters+1),epochs), np.array(curves_results[4][0])*100, 'b',label=r'$Porcentaje_{in}$', linewidth=2)\n",
        "plt.plot(range(epochs, epochs*(iters+1),epochs), np.array(curves_results[4][1])*100, 'orange',label=r'$Porcentaje_{out}$', linewidth=2)\n",
        "\n",
        "plt.legend(fontsize = 15)\n",
        "plt.grid(visible=True,linewidth=0.2) # poner la cuadricula con el grosor del resultado dado\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wlz3EGOpRG7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Porcentaje de soluciones mejores que Etiquetas"
      ],
      "metadata": {
        "id": "0mFt74QlRG7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 7))\n",
        "plt.title(\"Curva de Aprendizaje del Porcentaje de Mejores soluciones respecto de las Etiquetas\",fontsize = 15)\n",
        "plt.xlabel(\"Época\",fontsize = 15)\n",
        "plt.ylabel(\"Porcentaje de Mejores soluciones\",fontsize = 15)\n",
        "plt.plot(range(epochs, epochs*(iters+1),epochs), np.array(curves_results[5][0])*100, 'b',label=r'$Porcentaje_{in}$', linewidth=2)\n",
        "plt.plot(range(epochs, epochs*(iters+1),epochs), np.array(curves_results[5][1])*100, 'orange',label=r'$Porcentaje_{out}$', linewidth=2)\n",
        "\n",
        "plt.legend(fontsize = 15)\n",
        "plt.grid(visible=True,linewidth=0.2) # poner la cuadricula con el grosor del resultado dado\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VSxMW8YtRG7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Algoritmo Genetico\n"
      ],
      "metadata": {
        "id": "ogB1NuSPdrp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Funciones de adaptación"
      ],
      "metadata": {
        "id": "69hU6McWdrqD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "def convertir_vector_matriz(caso, N):\n",
        "    vector = caso[:int(N*(N-1)/2)]\n",
        "    matriz_ad = [[False for _ in range(N)] for _ in range(N)]\n",
        "    index = 0\n",
        "    for i in range(N):\n",
        "        for j in range(i + 1, N):\n",
        "            if vector[index]:\n",
        "                matriz_ad[i][j] = True\n",
        "                matriz_ad[j][i] = True\n",
        "            index += 1\n",
        "    return matriz_ad\n",
        "\n",
        "def concatenar_solucion_instancia(instancia,sol):\n",
        "    vector_transformado = []\n",
        "    for aux in instancia:\n",
        "        vector_transformado.append(aux)\n",
        "\n",
        "    for aux in sol:\n",
        "        vector_transformado.append(aux)\n",
        "\n",
        "    return vector_transformado\n",
        "\n",
        "\n",
        "def transformar_soluciones_no_factibles(instancia, sol):\n",
        "  sol_local = sol.copy()\n",
        "  N = len(sol_local)\n",
        "  matriz_ad = convertir_vector_matriz(instancia,N)\n",
        "  sin_cubrir = copy.deepcopy(matriz_ad)\n",
        "\n",
        "  # Iterar sobre la solución inicial y marcar las aristas cubiertas\n",
        "  for i, cubierto in enumerate(sol_local):\n",
        "      if cubierto:\n",
        "          for j in range(N):  # Modificar sin usar sintaxis de NumPy\n",
        "                sin_cubrir[j][i] = False\n",
        "                sin_cubrir[i][j] = False\n",
        "\n",
        "  # Verificar aristas restantes y añadir vértices a la solución si es necesario\n",
        "  for i in range(N):\n",
        "      for j in range(i + 1, N):\n",
        "          if sin_cubrir[i][j]:  # Si la arista entre i y j no está cubierta\n",
        "              sol_local[i] = True\n",
        "              for k in range(N):  # Modificar sin usar sintaxis de NumPy\n",
        "                  sin_cubrir[k][i] = False\n",
        "                  sin_cubrir[i][k] = False\n",
        "  return sol_local\n"
      ],
      "metadata": {
        "id": "3JaNWtsTdrqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Algoritmo genético simple"
      ],
      "metadata": {
        "id": "4YiDn3s3drqD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from random import getrandbits, randint\n",
        "\n",
        "def valor_fitness(instancia_local, caso):\n",
        "    N = len(instancia_local)\n",
        "    sin_cubrir = convertir_vector_matriz(caso, N)\n",
        "    valor_fit = np.sum(instancia_local)\n",
        "\n",
        "    for i, cubierto in enumerate(instancia_local):\n",
        "        if cubierto:\n",
        "            for j in range(N):\n",
        "                sin_cubrir[j][i] = False\n",
        "                sin_cubrir[i][j] = False\n",
        "\n",
        "    for i in range(N):\n",
        "        for j in range(i + 1, N):\n",
        "            if not instancia_local[i] and not instancia_local[j] and sin_cubrir[i][j]:\n",
        "                valor_fit += N\n",
        "\n",
        "    return valor_fit\n",
        "\n",
        "def media_fitness(poblacion, caso):\n",
        "    sum_tot = sum(valor_fitness(x, caso) for x in poblacion if valor_fitness(x, caso) != float('inf'))\n",
        "    num_validas = len([x for x in poblacion if valor_fitness(x, caso) != float('inf')])\n",
        "    return sum_tot / num_validas if num_validas > 0 else float('inf')\n",
        "\n",
        "def min_fitness(poblacion, caso):\n",
        "    valores_fitness = [valor_fitness(x, caso) for x in poblacion if valor_fitness(x, caso) != float('inf')]\n",
        "    return min(valores_fitness) if valores_fitness else float('inf')\n",
        "\n",
        "def generar_sol(num_vertices):\n",
        "    return [getrandbits(1) for _ in range(num_vertices)]\n",
        "\n",
        "def generar_pobl(num_sols, num_vertices):\n",
        "    return [generar_sol(num_vertices) for _ in range(num_sols)]\n",
        "\n",
        "def elegir_antecesor(valores, fitness_total, indice_a_ignorar):\n",
        "    acumulado = 0\n",
        "    valor_random = random.random()\n",
        "\n",
        "    if indice_a_ignorar != -1:\n",
        "        fitness_total -= valores[0][indice_a_ignorar]\n",
        "\n",
        "    for indice, i in enumerate(valores[0]):\n",
        "        if indice_a_ignorar == indice or i == float('inf'):\n",
        "            continue\n",
        "        acumulado += i\n",
        "        if acumulado / fitness_total >= valor_random:\n",
        "            return indice\n",
        "\n",
        "def cruzar(antecesor1, antecesor2, tipo='un_punto'):\n",
        "    if tipo == 'un_punto':\n",
        "        punto = random.randint(1, len(antecesor1) - 1)\n",
        "        hijo1 = antecesor1[:punto] + antecesor2[punto:]\n",
        "        hijo2 = antecesor2[:punto] + antecesor1[punto:]\n",
        "    elif tipo == 'dos_puntos':\n",
        "        punto1 = random.randint(1, len(antecesor1) - 2)\n",
        "        punto2 = random.randint(punto1 + 1, len(antecesor1) - 1)\n",
        "        hijo1 = antecesor1[:punto1] + antecesor2[punto1:punto2] + antecesor1[punto2:]\n",
        "        hijo2 = antecesor2[:punto1] + antecesor1[punto1:punto2] + antecesor2[punto2:]\n",
        "    return hijo1, hijo2\n",
        "\n",
        "def op_genetico(poblacion, caso, num_sols_total, tipo_cruce='un_punto', mut_prob=0.05):\n",
        "    soluciones = [[valor_fitness(x, caso), x] for x in poblacion]\n",
        "    soluciones.sort(key=lambda x: x[0])\n",
        "\n",
        "    nuevas_sols = []\n",
        "    while len(nuevas_sols) < num_sols_total:\n",
        "        antecesor1, antecesor2 = cruzar(soluciones[0][1], soluciones[1][1], tipo=tipo_cruce)\n",
        "        hijo1, hijo2 = cruzar(antecesor1, antecesor2, tipo=tipo_cruce)\n",
        "        nuevas_sols.append(hijo1)\n",
        "        if len(nuevas_sols) < num_sols_total:\n",
        "            nuevas_sols.append(hijo2)\n",
        "\n",
        "    for sol_act in nuevas_sols:\n",
        "        if mut_prob > random.random():\n",
        "            pos_to_mutate = randint(0, len(sol_act) - 1)\n",
        "            sol_act[pos_to_mutate] = 1 - sol_act[pos_to_mutate]\n",
        "\n",
        "    return nuevas_sols\n"
      ],
      "metadata": {
        "id": "nTyP5_YmdrqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(1)\n",
        "\n",
        "caso = trainX[12][:int(tamMatriz)]\n",
        "N = 20  # Número de vértices\n",
        "\n",
        "num_sols_total = 20\n",
        "iters = 100\n",
        "\n",
        "poblacion = generar_pobl(num_sols_total, N)\n",
        "\n",
        "valores_medios = [media_fitness(poblacion, caso)]\n",
        "valores_min = [min_fitness(poblacion, caso)]\n",
        "for i in range(iters):\n",
        "    poblacion = op_genetico(poblacion, caso, num_sols_total, tipo_cruce='dos_puntos')\n",
        "    valores_medios.append(media_fitness(poblacion, caso))\n",
        "    valores_min.append(min_fitness(poblacion, caso))\n",
        "\n",
        "print(\"Valores medios de fitness a lo largo de las iteraciones:\", valores_medios)\n",
        "print(\"Valores mínimos de fitness a lo largo de las iteraciones:\", valores_min)\n"
      ],
      "metadata": {
        "id": "NYyTzY7kdrqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.title(r\"Media del Valor $Fitness$ de la Población de Soluciones sin Red Neuronal\",fontsize = 15)\n",
        "plt.xlabel(\"Iteración\",fontsize = 15)\n",
        "plt.ylabel(r\"Valor $fitness$ medio\",fontsize = 15)\n",
        "plt.ylim( 5 , 25)\n",
        "plt.plot(range(iters+1), valores_medios,'b',label=r'$Fitness$ medio', linewidth=2)\n",
        "plt.legend(fontsize = 15,loc = 'upper right')\n",
        "plt.grid(visible=True,linewidth=0.2) # poner la cuadricula con el grosor del resultado dado\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.title(r\"Valor $Fitness$ Mínimo de la Población de Soluciones sin Red Neuronal\",fontsize = 15)\n",
        "plt.xlabel(\"Iteración\",fontsize = 15)\n",
        "plt.ylabel(r\"Valor $fitness$ mínimo\",fontsize = 15)\n",
        "plt.plot(range(iters+1), valores_min,'b',label=r'$Fitness$ máximo', linewidth=2)\n",
        "\n",
        "\n",
        "\n",
        "plt.legend(fontsize = 15,loc = 'upper right')\n",
        "plt.grid(visible=True,linewidth=0.2) # poner la cuadricula con el grosor del resultado dado\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0TF21vTqdrqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Algoritmo genético con Red Neuronal"
      ],
      "metadata": {
        "id": "GR41jilmdrqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(1)\n",
        "\n",
        "caso = trainX[12][:int(tamMatriz)]\n",
        "N = 20  # Número de vértices\n",
        "\n",
        "num_sols_total = 20\n",
        "iters = 100\n",
        "\n",
        "\n",
        "eps = 0.1\n",
        "atasco = 0\n",
        "red_prob = 0.2\n",
        "\n",
        "poblacion = generar_pobl(num_sols_total, N)\n",
        "\n",
        "valores_medios = [media_fitness(poblacion, caso)]\n",
        "valores_min = [min_fitness(poblacion, caso)]\n",
        "iters_modelo = []\n",
        "for i in range(iters):\n",
        "    poblacion = op_genetico(poblacion, caso, num_sols_total, tipo_cruce='dos_puntos')\n",
        "    valores_medios.append(media_fitness(poblacion, caso))\n",
        "    valores_min.append(min_fitness(poblacion, caso))\n",
        "    if valores_min[-1] < (valores_medios[-2]*(1+eps)) :\n",
        "        atasco += 1\n",
        "        if atasco >= 10:\n",
        "          iters_modelo.append(i)\n",
        "          atasco = 0\n",
        "          for sol_act in poblacion:\n",
        "           if red_prob > random.random():\n",
        "              y_pred = final_model.predict(np.array([concatenar_solucion_instancia(caso, sol_act)]),verbose=0)\n",
        "              umbral = 0.5\n",
        "              y_pred_binary = (y_pred >= umbral).astype(int)\n",
        "              sol_fact = transformar_soluciones_no_factibles(caso, y_pred_binary[0])\n",
        "              sol_act = sol_fact.tolist()\n",
        "    else: atasco = 0\n",
        "\n",
        "print(\"Valores medios de fitness a lo largo de las iteraciones:\", valores_medios)\n",
        "print(\"Valores mínimos de fitness a lo largo de las iteraciones:\", valores_min)"
      ],
      "metadata": {
        "id": "GicFuY0rdrqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.title(r\"Media del Valor $Fitness$ de la Población de Soluciones con Red Neuronal\",fontsize = 15)\n",
        "plt.xlabel(\"Iteración\",fontsize = 15)\n",
        "plt.ylabel(r\"Valor $fitness$ medio\",fontsize = 15)\n",
        "plt.plot(range(iters+1), valores_medios,'g',label=r'$Fitness$ Medio', linewidth=2)\n",
        "plt.scatter(iters_modelo, [valores_medios[i] for i in iters_modelo], color='purple', label='Llamada a la Red Neuronal', s=100, zorder=5)\n",
        "plt.ylim( 5 , 25)\n",
        "plt.legend(fontsize = 15,loc = 'upper right')\n",
        "plt.grid(visible=True,linewidth=0.2) # poner la cuadricula con el grosor del resultado dado\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.title(r\"Valor $Fitness$ Mínimo de la Población de Soluciones con Red Neuronal\",fontsize = 15)\n",
        "plt.xlabel(\"Iteración\",fontsize = 15)\n",
        "plt.ylabel(r\"Valor $fitness$ mínimo\",fontsize = 15)\n",
        "plt.plot(range(iters+1), valores_min,'g',label=r'$Fitness$ mínimo', linewidth=2)\n",
        "plt.scatter(iters_modelo, [valores_min[i] for i in iters_modelo], color='purple', label='Llamada a la Red Neuronal', s=100, zorder=5)\n",
        "\n",
        "plt.legend(fontsize = 15, loc = 'upper right')\n",
        "plt.grid(visible=True,linewidth=0.2) # poner la cuadricula con el grosor del resultado dado\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BOYjziO9drqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejemplos de Soluciones Generadas"
      ],
      "metadata": {
        "id": "R44vhygAdrqF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solución inicial"
      ],
      "metadata": {
        "id": "JYpOVMMRdrqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sol_ini = transformar_soluciones_no_factibles(caso,trainX[12][-20:])\n",
        "y_pred = final_model.predict(np.array([concatenar_solucion_instancia(caso,sol_ini)]),verbose=0)\n",
        "umbral = 0.5\n",
        "y_pred_binary = (y_pred >= umbral).astype(int)\n",
        "sol_fact = transformar_soluciones_no_factibles(caso, y_pred_binary[0])\n",
        "sol_act = sol_fact.tolist()\n",
        "print(\"Solución Inicial:\",sol_ini, \"Valor fitness:\", int(valor_fitness(sol_ini, caso)))\n",
        "print(\"Solución generada\",sol_act, \"Valor fitness:\", int(valor_fitness(sol_act, caso)))"
      ],
      "metadata": {
        "id": "bQurCaV6drqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solución etiqueta"
      ],
      "metadata": {
        "id": "wehyzHxAdrqG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sol_ini = transformar_soluciones_no_factibles(caso,trainY[12])\n",
        "y_pred = final_model.predict(np.array([concatenar_solucion_instancia(caso,sol_ini)]),verbose=0)\n",
        "umbral = 0.5\n",
        "y_pred_binary = (y_pred >= umbral).astype(int)\n",
        "sol_fact = transformar_soluciones_no_factibles(caso, y_pred_binary[0])\n",
        "sol_act = sol_fact.tolist()\n",
        "print(\"Solución Inicial:\",sol_ini, \"Valor fitness:\", int(valor_fitness(sol_ini, caso)))\n",
        "print(\"Solución generada\",sol_act, \"Valor fitness:\", int(valor_fitness(sol_act, caso)))"
      ],
      "metadata": {
        "id": "VuaGS-kfdrqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Otra solución distinta"
      ],
      "metadata": {
        "id": "v3Or0RWrb35Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sol_ini = transformar_soluciones_no_factibles(caso,trainY[7])\n",
        "y_pred = final_model.predict(np.array([concatenar_solucion_instancia(caso,sol_ini)]),verbose=0)\n",
        "umbral = 0.5\n",
        "y_pred_binary = (y_pred >= umbral).astype(int)\n",
        "sol_fact = transformar_soluciones_no_factibles(caso, y_pred_binary[0])\n",
        "sol_act = sol_fact.tolist()\n",
        "print(\"Solución Inicial:\",sol_ini, \"Valor fitness:\", int(valor_fitness(sol_ini, caso)))\n",
        "print(\"Solución generada\",sol_act, \"Valor fitness:\", int(valor_fitness(sol_act, caso)))"
      ],
      "metadata": {
        "id": "6mguIm6TdrqG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}